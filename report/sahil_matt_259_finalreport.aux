\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{jiao_lu_huynh_mitra_2015}
\citation{nvidia_all_gpus}
\citation{nvidia_concurrent}
\citation{wang_huang_el_ghazawi_2011}
\newlabel{sec:ug_topmatter}{{}{1}}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}}
\citation{wende_cordes_steinke_2012}
\citation{pai_thazhuthaveetil_govindarajan_2013}
\citation{jiao_lu_huynh_mitra_2015}
\citation{gregg_dorn_hazelwood_skadron_2016}
\citation{nvidia_spec}
\citation{michaelmichael}
\citation{michaelmichael}
\citation{nvidia_concurrent}
\citation{nvidia_concurrent}
\citation{nvidia_concurrent}
\citation{nvidia_concurrent}
\citation{wende_cordes_steinke_2012}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Exploring Streams and Concurrent Kernels}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Creating a Set of Kernels }{2}{subsection.3.2}}
\citation{wende_cordes_steinke_2012}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Cuda streams API example. Taken from the Nvidia Concurrent Kernel PowerPoint. \citep  {nvidia_concurrent}\relax }}{3}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cuda concurrent kernel execution schedule. Taken from the Nvidia Concurrent Kernel PowerPoint. \citep  {nvidia_concurrent}\relax }}{3}{figure.caption.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Profiling Latency and Throughput}{3}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Creating Batched Kernels}{3}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{3}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{4}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Sequential vs Concurrent Convolution 1}{4}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Sequential vs Concurrent vs Batched Convolution 2}{4}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Sequential vs Concurrent vs Batched Classifier}{4}{subsection.5.3}}
\citation{wende_cordes_steinke_2012}
\bibstyle{ACM-Reference-Format}
\bibdata{bibliography}
\bibcite{nvidia_all_gpus}{{1}{2019}{{nvi}}{{??}}}
\bibcite{michaelmichael}{{2}{[n. d.]}{{3 et~al\unhbox \voidb@x \hbox {.}}}{{3, 1, and srodrbsrodrb 979920}}}
\bibcite{gregg_dorn_hazelwood_skadron_2016}{{3}{2016}{{Gregg et~al\unhbox \voidb@x \hbox {.}}}{{Gregg, Dorn, Hazelwood, and Skadron}}}
\bibcite{jiao_lu_huynh_mitra_2015}{{4}{2015}{{Jiao et~al\unhbox \voidb@x \hbox {.}}}{{Jiao, Lu, Huynh, and Mitra}}}
\bibcite{nvidia_spec}{{5}{[n. d.]a}{{Nvidia}}{{Nvidia}}}
\bibcite{nvidia_concurrent}{{6}{[n. d.]b}{{Nvidia}}{{Nvidia}}}
\bibcite{pai_thazhuthaveetil_govindarajan_2013}{{7}{2013}{{Pai et~al\unhbox \voidb@x \hbox {.}}}{{Pai, Thazhuthaveetil, and Govindarajan}}}
\bibcite{wang_huang_el_ghazawi_2011}{{8}{2011}{{Wang et~al\unhbox \voidb@x \hbox {.}}}{{Wang, Huang, and ElGhazawi}}}
\bibcite{wende_cordes_steinke_2012}{{9}{2012}{{Wende et~al\unhbox \voidb@x \hbox {.}}}{{Wende, Cordes, and Steinke}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}AWS M60 Results}{5}{subsection.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{5}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Statement of Work}{5}{section.7}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.6}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendices}{6}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Tesla V100 GPU Graphs}{6}{subsection.A.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Sequential and concurrent convolution performance.\relax }}{6}{figure.caption.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sequential and concurrent convolution 2 performance.\relax }}{7}{figure.caption.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Batched convolution 2 performance.\relax }}{8}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sequential and concurrent classifier performance.\relax }}{9}{figure.caption.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Batched classifier performance.\relax }}{10}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}AWS M60 GPU Graphs}{11}{subsection.A.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sequential and concurrent convolution performance.\relax }}{11}{figure.caption.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Sequential and concurrent convolution 2 performance.\relax }}{12}{figure.caption.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Batched convolution 2 performance.\relax }}{13}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Sequential and concurrent classifier performance.\relax }}{14}{figure.caption.15}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{8.37pt}
\newlabel{tocindent2}{12.41998pt}
\newlabel{tocindent3}{0pt}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Batched classifier performance.\relax }}{15}{figure.caption.16}}
\newlabel{TotPages}{{15}{15}{}{page.15}{}}
